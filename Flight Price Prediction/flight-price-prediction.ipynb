{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n!pip3 install -U lazypredict\n!pip3 install -U pandas\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:33:03.266614Z","iopub.execute_input":"2022-04-16T07:33:03.266998Z","iopub.status.idle":"2022-04-16T07:34:22.658837Z","shell.execute_reply.started":"2022-04-16T07:33:03.266895Z","shell.execute_reply":"2022-04-16T07:34:22.657998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n%matplotlib inline","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-04-16T07:34:22.660795Z","iopub.execute_input":"2022-04-16T07:34:22.661039Z","iopub.status.idle":"2022-04-16T07:34:22.670734Z","shell.execute_reply.started":"2022-04-16T07:34:22.660991Z","shell.execute_reply":"2022-04-16T07:34:22.669694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/flight-price-prediction/Clean_Dataset.csv', index_col=False)\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:34:22.672339Z","iopub.execute_input":"2022-04-16T07:34:22.672809Z","iopub.status.idle":"2022-04-16T07:34:23.461312Z","shell.execute_reply.started":"2022-04-16T07:34:22.672779Z","shell.execute_reply":"2022-04-16T07:34:23.460664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(data.columns[0], axis=1)\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:34:23.462839Z","iopub.execute_input":"2022-04-16T07:34:23.463202Z","iopub.status.idle":"2022-04-16T07:34:23.506403Z","shell.execute_reply.started":"2022-04-16T07:34:23.463172Z","shell.execute_reply":"2022-04-16T07:34:23.505489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Validate if there are no missing values in the dataframe.","metadata":{}},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:34:23.507847Z","iopub.execute_input":"2022-04-16T07:34:23.508649Z","iopub.status.idle":"2022-04-16T07:34:23.775893Z","shell.execute_reply.started":"2022-04-16T07:34:23.508598Z","shell.execute_reply":"2022-04-16T07:34:23.774369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encode the categorical variables\n\nFrom exploratory analysis, it looks like there are a number of categorical data types. By look at 'object' types below, we can see there are 8 entries that are categorial in nature. After we see the categorical variables, we can convert them categories into numerical values using One Hot Encoding method.","metadata":{}},{"cell_type":"code","source":"columns = [\"airline\", \"source_city\", \"departure_time\", \"stops\", \"destination_city\", \"class\", \"days_left\"]\nfor col in columns:\n    items = data[col].unique()\n    print(\"Column:{} Counts:{} Items:{}\".format(col, len(items), items))","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:34:23.777056Z","iopub.execute_input":"2022-04-16T07:34:23.777293Z","iopub.status.idle":"2022-04-16T07:34:23.925535Z","shell.execute_reply.started":"2022-04-16T07:34:23.777248Z","shell.execute_reply":"2022-04-16T07:34:23.924722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ncat_columns = ['airline', \n               'source_city', \n               'departure_time', \n               'stops', \n               'arrival_time', \n               'destination_city',\n               'class']\n\nohe = OneHotEncoder(handle_unknown='ignore')\n\nohe_df =  pd.DataFrame(ohe.fit_transform(data[cat_columns]).toarray())\n\nohe_df.columns = ohe.get_feature_names(cat_columns)\n\ndata.drop(cat_columns, axis = 1, inplace = True)\n\ndata = data.join(ohe_df)\ndata.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:34:23.926686Z","iopub.execute_input":"2022-04-16T07:34:23.926902Z","iopub.status.idle":"2022-04-16T07:34:25.793837Z","shell.execute_reply.started":"2022-04-16T07:34:23.926875Z","shell.execute_reply":"2022-04-16T07:34:25.793196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling the continous variables\n\nWe next deal with the continuous variables to have a consistent scale, using the StandardScaler function. First, we look at the columns where the data range is not within [0.0, 1.0]. duration is the column that requires scaling.","metadata":{}},{"cell_type":"code","source":"stats = data.agg(['min', 'max'])\n\nfor col in data.columns:\n    if data[col].dtype.type is np.object_:\n        continue\n\n    if stats[col].max() > 1.0:\n        print(\"Column Name: {}, Min: {}, Max: {}\".format(col, stats[col].min(), stats[col].max()))","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:34:25.795041Z","iopub.execute_input":"2022-04-16T07:34:25.795716Z","iopub.status.idle":"2022-04-16T07:34:25.980918Z","shell.execute_reply.started":"2022-04-16T07:34:25.795681Z","shell.execute_reply":"2022-04-16T07:34:25.980022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndata['duration'] = scaler.fit_transform(np.array(data['duration']).reshape(-1,1))\ndata.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:34:25.98229Z","iopub.execute_input":"2022-04-16T07:34:25.982532Z","iopub.status.idle":"2022-04-16T07:34:26.031474Z","shell.execute_reply.started":"2022-04-16T07:34:25.982501Z","shell.execute_reply":"2022-04-16T07:34:26.03088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline Model Evaluation\n\nWe have no idea which model will do well on this data. Let's design a test harness with 10-fold cross-validation. We will evaluate algorithms using the Mean Squared Error (MSE) metric. MSE will give a gross idea of how wrong all predictions are (0 being perfect)","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:43:24.719494Z","iopub.execute_input":"2022-04-16T07:43:24.722295Z","iopub.status.idle":"2022-04-16T07:43:24.726731Z","shell.execute_reply.started":"2022-04-16T07:43:24.722226Z","shell.execute_reply":"2022-04-16T07:43:24.726031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare training data\n\nNow prepare the train-test set from the original data set. The train-test ratio shall be 80:20.","metadata":{}},{"cell_type":"code","source":"train_X = data.drop(columns=['flight','price'])\ntrain_Y = data['price']\n\n# randomly split the data\ntrain_x, test_x, train_y, test_y = train_test_split(train_X, train_Y,test_size=0.20, random_state=21)\n\n# shape of train and test splits\ntrain_x.shape, test_x.shape, train_y.shape, test_y.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:34:26.111728Z","iopub.execute_input":"2022-04-16T07:34:26.112039Z","iopub.status.idle":"2022-04-16T07:34:26.467076Z","shell.execute_reply.started":"2022-04-16T07:34:26.111985Z","shell.execute_reply":"2022-04-16T07:34:26.46621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training and Evaluation\n\nWe have no idea which model will do well on this data. Let's design a test harness with 10-fold cross-validation. We will evaluate algorithms using the Mean Squared Error (MSE) metric. MSE will give a gross idea of how wrong all predictions are (0 being perfect). In addition, I extract a data sample that extract only 5% of the train set for the test harness - this is to enable the test harness to complete quickly.","metadata":{}},{"cell_type":"code","source":"sample_data = data.sample(frac=0.01)\nsample_x = sample_data.drop(columns=['flight','price'])\nsample_y = sample_data['price']\n\nsample_train_x, sample_test_x, sample_train_y, sample_test_y = train_test_split(sample_x, sample_y,test_size=0.20, random_state=21)\nsample_train_x.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:41:16.728524Z","iopub.execute_input":"2022-04-16T07:41:16.729172Z","iopub.status.idle":"2022-04-16T07:41:16.751535Z","shell.execute_reply.started":"2022-04-16T07:41:16.72913Z","shell.execute_reply":"2022-04-16T07:41:16.750905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lazypredict\nfrom lazypredict.Supervised import LazyRegressor","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:34:26.494973Z","iopub.execute_input":"2022-04-16T07:34:26.495301Z","iopub.status.idle":"2022-04-16T07:34:27.775273Z","shell.execute_reply.started":"2022-04-16T07:34:26.495258Z","shell.execute_reply":"2022-04-16T07:34:27.774291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg = LazyRegressor(verbose=0,\n                    ignore_warnings=True, \n                    custom_metric=None,\n                    random_state=12)\n\nmodels, predictions = reg.fit(sample_train_x, sample_test_x, sample_train_y, sample_test_y)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:41:21.520909Z","iopub.execute_input":"2022-04-16T07:41:21.521279Z","iopub.status.idle":"2022-04-16T07:41:36.059429Z","shell.execute_reply.started":"2022-04-16T07:41:21.521239Z","shell.execute_reply":"2022-04-16T07:41:36.058776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:41:38.795591Z","iopub.execute_input":"2022-04-16T07:41:38.796232Z","iopub.status.idle":"2022-04-16T07:41:38.811774Z","shell.execute_reply.started":"2022-04-16T07:41:38.796185Z","shell.execute_reply":"2022-04-16T07:41:38.810789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, GridSearchCV\n\nmodel = XGBRegressor()\nk = 10\nparam_grid = {'learning_rate': [0.2, 0.15, 0.1, 0.05],\n              'n_estimators' : [50,100,200,300,400]}\n\nskfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=21)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, scoring='neg_mean_squared_error', cv=skfold)\nstart = time.time()\ngrid_result = grid.fit(train_x, train_y)\nend = time.time()\n\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"MSE: {:.4f} STD: {:.4f} with: {}\".format(mean, stdev, param))\n\nprint(\"Best: {:.4f} using {} (run time : {:.3f})\".format(grid_result.best_score_, grid_result.best_params_, end-start))","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:48:35.357218Z","iopub.execute_input":"2022-04-16T07:48:35.358143Z","iopub.status.idle":"2022-04-16T07:50:23.611913Z","shell.execute_reply.started":"2022-04-16T07:48:35.358096Z","shell.execute_reply":"2022-04-16T07:50:23.611082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = XGBRegressor()\nmodel.set_params(**grid.best_params_)\n\nprint(\"Training model with best parameters={}\".format(grid.best_params_))\nstart = time.time()\nmodel.fit(train_x, train_y)\nend = time.time()\n\nprint(\"Training completed with run time {:.3f} seconds\".format(end-start))","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:50:29.918583Z","iopub.execute_input":"2022-04-16T07:50:29.918925Z","iopub.status.idle":"2022-04-16T07:50:40.169993Z","shell.execute_reply.started":"2022-04-16T07:50:29.918883Z","shell.execute_reply":"2022-04-16T07:50:40.169263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Validate model on test set\")\npredict_test = model.predict(test_x)\nprint('RMSE on test data: {:.4f}'.format(mean_squared_error(test_y, predict_test)**(0.5)))","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:50:44.033816Z","iopub.execute_input":"2022-04-16T07:50:44.034664Z","iopub.status.idle":"2022-04-16T07:50:44.151939Z","shell.execute_reply.started":"2022-04-16T07:50:44.034617Z","shell.execute_reply":"2022-04-16T07:50:44.151087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation (compare prediction against ground truths)","metadata":{}},{"cell_type":"code","source":"diff = abs(test_y - predict_test)\npercent_diff = diff/test_y * 100\n\ncompare = pd.DataFrame({'Ground Truths' : test_y, \n                        'Prediction': predict_test.round(decimals=2), \n                        'Difference': diff.round(decimals=2),\n                        '% Difference': percent_diff.round(decimals=2)})\ncompare.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:50:47.036126Z","iopub.execute_input":"2022-04-16T07:50:47.036731Z","iopub.status.idle":"2022-04-16T07:50:47.05581Z","shell.execute_reply.started":"2022-04-16T07:50:47.036677Z","shell.execute_reply":"2022-04-16T07:50:47.054854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\n\njoblib.dump(model, \"model.joblib\")","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:40:45.817244Z","iopub.status.idle":"2022-04-16T07:40:45.817692Z","shell.execute_reply.started":"2022-04-16T07:40:45.81745Z","shell.execute_reply":"2022-04-16T07:40:45.817473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model training with only the more important features\n\nAfter the preprocessing and encoding steps, the train data set has a total of 37 attributes which not all are useful in forecasting the prices. We can select the top attributes that have the bigger contribution in forecasting price values. Using less attributes to train a comparable model will result in a less complex model. From the chart below, there are only 4 attributes that seem to have a bigger impact on the model (quite intuitively so).","metadata":{}},{"cell_type":"code","source":"# plot the 15 most important features \nplt.figure(figsize=(10, 7))\nfeat_importances = pd.Series(model.feature_importances_, index = train_x.columns)\nfeat_importances.nlargest(15).plot(kind='barh');\nplt.xlabel('Importance Score')\nplt.ylabel('Attribute Labels')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T07:51:05.189102Z","iopub.execute_input":"2022-04-16T07:51:05.189742Z","iopub.status.idle":"2022-04-16T07:51:05.497535Z","shell.execute_reply.started":"2022-04-16T07:51:05.189695Z","shell.execute_reply":"2022-04-16T07:51:05.496481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impact_columns = ['class_Business', \n                  'class_Economy',\n                  'duration',\n                  'days_left', \n                  'airline_Vistara', \n                  'airline_Air_India', \n                  'source_city_Delhi', \n                  'destination_city_Delhi', \n                  'source_city_Mumbai', \n                  'destination_city_Mumbai']\n\ntrain_x_if = train_x[impact_columns]\ntest_x_if = test_x[impact_columns]\n\nmodel_with_if = XGBRegressor(random_state=21, \n                             n_estimators=grid.best_params_['n_estimators'],\n                             learning_rate=grid.best_params_['learning_rate'])\n\n# fit the model with the training data\nstart = time.time()\nmodel_with_if.fit(train_x_if, train_y)\nend = time.time()\nprint(\"Training completed with run time {:.3f} seconds\".format(end-start))\n\n# predict the target on the training and test data\nprint(\"Validate model on train set\")\npredict_train_with_if = model_with_if.predict(train_x_if)\nprint('RMSE on train data: ', mean_squared_error(train_y, predict_train_with_if)**(0.5))\n\nprint(\"Validate model on test set\")\npredict_test_with_if = model_with_if.predict(test_x_if)\nprint('RMSE on test data: ',  mean_squared_error(test_y, predict_test_with_if)**(0.5))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}