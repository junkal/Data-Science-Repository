{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting age profile of Abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the age profile of Abalone from physical measurements.  The age of abalone is determined by cutting the shell through the cone, staining it,and counting the number of rings through a microscope -- a boring and time-consuming task. Other measurements, which are easier to obtain, are used to predict the age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "Load the dataset and do some quick exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Sex', 'Length', 'Diameter', 'Height', 'Whole_weight','Shucked_weight', \n",
    "                 'Viscera_weight', 'Shell_weight', 'Rings']\n",
    "data = pd.read_csv('abalone.txt', index_col=False, delimiter = \",\", names=column_names)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation and pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the number of Male, Female and Infant samples from the dataset. From the output shown below, the distribution between the 3 categories is balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby('Sex').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we visualise the data using density plots to get a sense of the data distribution. From the outputs below, you can see the data shows a general gaussian distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='density', subplots=True, layout=(4,4), sharex=False, legend=False, fontsize=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good to check the correlations between the attributes. From the output graph below, The red around\n",
    "the diagonal suggests that attributes are correlated with each other. The yellow and green patches suggest some moderate correlation and the blue boxes show negative correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "correlation_map = data.corr(method='pearson')\n",
    "sns.set(font_scale=1.0)\n",
    "sns.heatmap(correlation_map, cbar=True, annot=True, square=True, fmt='.2f', \n",
    "            yticklabels=correlation_map.columns.values, \n",
    "            xticklabels=correlation_map.columns.values)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = {'M': 1, 'F': 2, 'I': 0}\n",
    "# Use the dictionary to map the 'winner' column to the new column: election['color']\n",
    "data['Sex'] = data.Sex.map(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = data['Rings'].values\n",
    "X = data.drop('Rings', axis=1).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.20, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline algorithm checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('LASSO', Lasso()))\n",
    "models.append(('EN', ElasticNet()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('CART', DecisionTreeRegressor()))\n",
    "models.append(('SVR', SVR()))\n",
    "models.append(('GBR', GradientBoostingRegressor()))\n",
    "models.append(('AB', AdaBoostRegressor()))\n",
    "models.append(('RF', RandomForestRegressor()))\n",
    "models.append(('ET', ExtraTreesRegressor()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=21)\n",
    "    start = time.time()\n",
    "    cv_results = abs(cross_val_score(model, X_train, Y_train, cv=kfold, scoring='neg_mean_squared_error'))\n",
    "    end = time.time()\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print( \"%s: RMSE %f (STD %f) (run time: %f)\" % (name, sqrt(cv_results.mean()), cv_results.std(), end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Performance Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the initial run, it looks like Gradient Boosting Method performed the best given the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = dict(n_estimators=np.array([50,100,200,300,400, 500]))\n",
    "model = GradientBoostingRegressor(random_state=21)\n",
    "kfold = KFold(n_splits=10, random_state=21)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=kfold)\n",
    "start = time.time()\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "end = time.time()\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (sqrt(abs(mean)), stdev, param))\n",
    "\n",
    "print(\"Best: %f using %s (run time :%f)\" % (sqrt(abs(grid_result.best_score_)), grid_result.best_params_, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best n_estimator configuration is 100 with the root mean square error closest to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=21, n_estimators=100)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# transform the validation dataset\n",
    "predictions = np.round(model.predict(X_test),0)\n",
    "print (sqrt(mean_squared_error(Y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame({'Prediction': predictions, 'Test Data' : Y_test})\n",
    "compare.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Let's take a look what are the important features GBR used to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.drop('Rings', axis = 1)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "priority = pd.DataFrame({'Attribute Label': train.columns, 'Feature Importances': model.feature_importances_})\n",
    "priority = priority.sort_values('Feature Importances', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Feature Importance Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.bar(range(len(priority)), priority['Feature Importances'])\n",
    "ax.set_xticks(np.arange(len(priority['Attribute Label'])))\n",
    "ax.set_xticklabels(priority['Attribute Label'], rotation=70)\n",
    "plt.ylabel('Importance Score')\n",
    "plt.xlabel('Attribute Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Neural Network to predict the age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise Model\n",
    "n_cols = X_train.shape[1] # Save the number of columns in predictors: n_cols\n",
    "model = Sequential()\n",
    "model.add(Dense(2*n_cols, activation='relu', input_shape=(n_cols,))) # Add the first layer\n",
    "model.add(Dense(32, activation='relu')) #Add the second layer\n",
    "model.add(Dense(1)) # Add the output layer, 1 neuron\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#initiate the optimizer\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) \n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating on testing set...\")\n",
    "model.fit(X_train, Y_train, epochs=500, validation_split=0.2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = sqrt(model.evaluate(X_test, Y_test, verbose=True))\n",
    "print(\"[INFO] SQRT loss={:.3f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = np.round(model.predict(X_test), 0).tolist()\n",
    "predictions = model.predict(X_test).tolist()\n",
    "predictions = [item for items in predictions for item in items]\n",
    "compare = pd.DataFrame({'Prediction': predictions, 'Test Data' : Y_test})\n",
    "compare.Prediction = compare.Prediction.astype(int)\n",
    "compare.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "f9SY5",
   "launcher_item_id": "oxndk",
   "part_id": "mh1Vo"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
